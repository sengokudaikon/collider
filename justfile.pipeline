#!/usr/bin/env just --justfile

# Mega pipeline justfile for comprehensive testing and benchmarking workflows
# Usage: just -f justfile.pipeline <recipe>

# Default recipe
default:
    @just --list

# ==== Mega Pipeline ====

# Complete workflow: docker test up â†’ coverage tests â†’ shutdown test â†’ dev up â†’ all benchmarks
mega-pipeline:
    #!/usr/bin/env bash
    set -e
    echo "ðŸš€ Starting Mega Pipeline - Complete Test & Benchmark Workflow"
    echo "============================================================="
    
    # Create results directory with timestamp
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    RESULTS_DIR="pipeline_results/mega_pipeline_$TIMESTAMP"
    mkdir -p "$RESULTS_DIR"
    
    echo "ðŸ“ Results will be saved to: $RESULTS_DIR"
    
    # Phase 1: Test Environment + Coverage
    echo ""
    echo "ðŸ§ª Phase 1: Test Environment + Coverage Testing"
    echo "==============================================="
    
    echo "Starting test environment..."
    docker compose -f docker-compose.test.yml up -d
    docker compose -f docker-compose.test.yml run --rm wait-for-services
    
    echo "Setting up test database..."
    DATABASE_URL="postgresql://postgres:postgres@localhost:5433/test_db" \
    cargo run --bin migrator -- up
    
    echo "Running comprehensive tests with coverage..."
    DATABASE_URL="postgres://postgres:postgres@localhost:5433/test_db" \
    REDIS_URL="redis://localhost:6380" \
    cargo tarpaulin --all --out Html --out Json --output-dir "$RESULTS_DIR" --timeout 180
    
    echo "Shutting down test environment..."
    docker compose -f docker-compose.test.yml down -v
    
    # Phase 2: Development Environment Setup
    echo ""
    echo "ðŸ—ï¸  Phase 2: Development Environment Setup"
    echo "=========================================="
    
    echo "Starting development environment..."
    docker compose up -d
    
    echo "Waiting for services to be ready..."
    sleep 15
    
    echo "Setting up development database..."
    DATABASE_URL="postgres://postgres:postgres@localhost:5432/events" \
    cargo run --bin migrator -- up
    
    DATABASE_URL="postgres://postgres:postgres@localhost:5432/events" \
    cargo run --bin seeder -- all --min-users 1000 --max-users 5000 --target-events 100000
    
    # Wait for app to be ready
    echo "Waiting for application to be ready..."
    until curl -f http://localhost:8080/health &>/dev/null; do
        echo "  Waiting for app..."
        sleep 5
    done
    echo "âœ… Application ready!"
    
    # Phase 3: Comprehensive Benchmarking
    echo ""
    echo "ðŸ“Š Phase 3: Comprehensive Benchmarking"
    echo "======================================"
    
    # Start monitoring in background
    {
        echo "Starting performance monitoring..."
        while true; do
            echo "=== $(date) ===" >> "$RESULTS_DIR/system_monitor.log"
            docker stats --no-stream >> "$RESULTS_DIR/system_monitor.log"
            echo "" >> "$RESULTS_DIR/system_monitor.log"
            sleep 10
        done
    } &
    MONITOR_PID=$!
    
    # Run all benchmarks with output capture
    {
        echo "ðŸ”¬ Running Criterion benchmarks..."
        cargo bench --package collider-benchmarks 2>&1
        
        echo ""
        echo "ðŸš€ Running K6 load tests..."
        docker run --rm --network collider \
            -v $(pwd)/infrastructure/benchmarking/k6:/scripts \
            grafana/k6:latest run /scripts/load-test.js 2>&1 || echo "K6 test completed with warnings"
        
        echo ""
        echo "ðŸ¦† Running Goose load tests..."
        cd infrastructure/benchmarking
        timeout 300s cargo run --bin goose_load_test 2>&1 || echo "Goose test completed/timed out"
        cd ../..
        
        echo ""
        echo "âš¡ Running Vegeta tests..."
        cd infrastructure/benchmarking
        timeout 120s ./run_load_test.sh localhost:8080 2>&1 || echo "Vegeta test completed/timed out"
        cd ../..
        
    } | tee "$RESULTS_DIR/benchmark_output.log"
    
    # Stop monitoring
    kill $MONITOR_PID 2>/dev/null || true
    
    # Phase 4: Performance Analysis
    echo ""
    echo "ðŸ“ˆ Phase 4: Performance Analysis"
    echo "==============================="
    
    # Collect final metrics
    echo "Collecting final application metrics..."
    curl -s http://localhost:8080/metrics > "$RESULTS_DIR/final_metrics.txt" 2>/dev/null || echo "Metrics not available"
    
    # Container stats
    echo "Collecting container statistics..."
    docker stats --no-stream > "$RESULTS_DIR/final_docker_stats.txt"
    
    # Binary analysis
    echo "Analyzing binary size..."
    cargo bloat --release --crates > "$RESULTS_DIR/binary_analysis.txt" 2>/dev/null || true
    
    echo ""
    echo "âœ… Mega Pipeline Complete!"
    echo "========================="
    echo "ðŸ“ Results directory: $RESULTS_DIR"
    echo "ðŸ“Š Coverage report: $RESULTS_DIR/tarpaulin-report.html"
    echo "ðŸ“ˆ Benchmark output: $RESULTS_DIR/benchmark_output.log"
    echo "ðŸ“‹ System monitoring: $RESULTS_DIR/system_monitor.log"
    echo ""
    echo "ðŸ”§ Development environment is still running at:"
    echo "   Application: http://localhost:8080"
    echo "   Prometheus: http://localhost:9090"
    echo "   Grafana: http://localhost:3000"
    echo ""
    echo "Use 'just -f justfile.pipeline stop-dev' to shut down"

# Stop development environment
stop-dev:
    docker compose down
    @echo "âœ… Development environment stopped"

# Quick pipeline (reduced scope for faster execution)
quick-pipeline:
    #!/usr/bin/env bash
    set -e
    echo "âš¡ Quick Pipeline - Fast Test & Benchmark Workflow"
    echo "================================================="
    
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    RESULTS_DIR="pipeline_results/quick_pipeline_$TIMESTAMP"
    mkdir -p "$RESULTS_DIR"
    
    # Quick tests
    echo "ðŸ§ª Running quick tests..."
    docker compose -f docker-compose.test.yml up -d
    docker compose -f docker-compose.test.yml run --rm wait-for-services
    
    DATABASE_URL="postgres://postgres:postgres@localhost:5433/test_db" \
    REDIS_URL="redis://localhost:6380" \
    cargo test --all | tee "$RESULTS_DIR/test_output.log"
    
    docker compose -f docker-compose.test.yml down -v
    
    # Quick dev setup
    echo "ðŸ—ï¸  Starting dev environment..."
    docker compose up -d
    sleep 10
    
    # Quick benchmarks
    echo "ðŸ“Š Running quick benchmarks..."
    {
        cargo bench --package collider-benchmarks -- --sample-size 10 --measurement-time 5 2>&1
    } | tee "$RESULTS_DIR/quick_benchmark.log"
    
    echo "âœ… Quick Pipeline Complete! Results in: $RESULTS_DIR"

# Coverage-only pipeline
coverage-pipeline:
    #!/usr/bin/env bash
    set -e
    echo "ðŸ§ª Coverage Pipeline - Comprehensive Test Coverage"
    echo "================================================="
    
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    RESULTS_DIR="pipeline_results/coverage_$TIMESTAMP"
    mkdir -p "$RESULTS_DIR"
    
    # Start test environment
    docker compose -f docker-compose.test.yml up -d
    docker compose -f docker-compose.test.yml run --rm wait-for-services
    
    # Setup database
    DATABASE_URL="postgresql://postgres:postgres@localhost:5433/test_db" \
    cargo run --bin migrator -- up
    
    # Run comprehensive coverage
    DATABASE_URL="postgres://postgres:postgres@localhost:5433/test_db" \
    REDIS_URL="redis://localhost:6380" \
    cargo tarpaulin --all --out Html --out Json --out Lcov --output-dir "$RESULTS_DIR" --timeout 300 --fail-under 75
    
    # Cleanup
    docker compose -f docker-compose.test.yml down -v
    
    echo "âœ… Coverage analysis complete!"
    echo "ðŸ“Š HTML Report: $RESULTS_DIR/tarpaulin-report.html"
    echo "ðŸ“‹ JSON Report: $RESULTS_DIR/tarpaulin-report.json"

# Benchmark-only pipeline
benchmark-pipeline:
    #!/usr/bin/env bash
    set -e
    echo "ðŸ“Š Benchmark Pipeline - Comprehensive Performance Testing"
    echo "========================================================"
    
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    RESULTS_DIR="pipeline_results/benchmarks_$TIMESTAMP"
    mkdir -p "$RESULTS_DIR"
    
    # Start dev environment
    docker compose up -d
    sleep 15
    
    # Setup with more data for realistic benchmarks
    DATABASE_URL="postgres://postgres:postgres@localhost:5432/events" \
    cargo run --bin migrator -- up
    
    DATABASE_URL="postgres://postgres:postgres@localhost:5432/events" \
    cargo run --bin seeder -- all --min-users 5000 --max-users 10000 --target-events 1000000
    
    # Wait for app
    until curl -f http://localhost:8080/health &>/dev/null; do
        sleep 5
    done
    
    # Comprehensive benchmarks
    {
        echo "=== Criterion Micro-benchmarks ==="
        cargo bench --package collider-benchmarks
        
        echo ""
        echo "=== K6 Load Testing ==="
        docker run --rm --network collider \
            -v $(pwd)/infrastructure/benchmarking/k6:/scripts \
            grafana/k6:latest run /scripts/scenarios/endurance-test.js
        
        echo ""
        echo "=== Goose Rust Load Testing ==="
        cd infrastructure/benchmarking
        timeout 600s cargo run --bin goose_load_test
        cd ../..
        
        echo ""
        echo "=== Performance Profiling ==="
        cargo bloat --release --crates
        
    } | tee "$RESULTS_DIR/comprehensive_benchmarks.log"
    
    # Collect metrics
    curl -s http://localhost:8080/metrics > "$RESULTS_DIR/app_metrics.txt" || true
    docker stats --no-stream > "$RESULTS_DIR/container_stats.txt"
    
    echo "âœ… Comprehensive benchmarking complete!"
    echo "ðŸ“ Results: $RESULTS_DIR"

# Performance regression testing pipeline
regression-pipeline baseline_dir:
    #!/usr/bin/env bash
    set -e
    echo "ðŸ” Regression Pipeline - Performance Regression Detection"
    echo "========================================================"
    
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    RESULTS_DIR="pipeline_results/regression_$TIMESTAMP"
    mkdir -p "$RESULTS_DIR"
    
    # Run current benchmarks
    just -f justfile.pipeline benchmark-pipeline
    
    # Compare with baseline (basic comparison)
    if [ -d "{{baseline_dir}}" ]; then
        echo "ðŸ“Š Comparing with baseline: {{baseline_dir}}"
        
        echo "=== Benchmark Comparison ===" > "$RESULTS_DIR/regression_analysis.txt"
        echo "Baseline: {{baseline_dir}}" >> "$RESULTS_DIR/regression_analysis.txt"
        echo "Current: pipeline_results/benchmarks_*" >> "$RESULTS_DIR/regression_analysis.txt"
        echo "" >> "$RESULTS_DIR/regression_analysis.txt"
        
        # Simple file size comparison as proxy for performance
        echo "File size comparison (rough performance indicator):" >> "$RESULTS_DIR/regression_analysis.txt"
        du -sh {{baseline_dir}}/* >> "$RESULTS_DIR/regression_analysis.txt" || true
        du -sh pipeline_results/benchmarks_*/comprehensive_benchmarks.log >> "$RESULTS_DIR/regression_analysis.txt" || true
        
        echo "âœ… Regression analysis complete!"
        echo "ðŸ“‹ Analysis: $RESULTS_DIR/regression_analysis.txt"
    else
        echo "âš ï¸  Baseline directory not found: {{baseline_dir}}"
        echo "Current results can be used as baseline for future comparisons"
    fi

# Clean all pipeline results
clean:
    rm -rf pipeline_results/
    rm -rf target/criterion/
    rm -rf coverage/
    @echo "âœ… All pipeline results cleaned"

# Show pipeline results
results:
    @echo "ðŸ“Š Pipeline Results"
    @echo "=================="
    @find pipeline_results -name "*.log" -o -name "*.html" -o -name "*.json" 2>/dev/null | head -20 || echo "No results found"
    @echo ""
    @echo "Latest results:"
    @ls -la pipeline_results/ 2>/dev/null | tail -10 || echo "No pipeline results directory"

# Help for pipeline commands
help:
    @echo "ðŸš€ Collider Pipeline Commands"
    @echo "============================"
    @echo ""
    @echo "Main Pipelines:"
    @echo "  just -f justfile.pipeline mega-pipeline      # Complete workflow (2-3 hours)"
    @echo "  just -f justfile.pipeline quick-pipeline     # Fast workflow (10-15 min)"
    @echo ""
    @echo "Specialized Pipelines:"
    @echo "  just -f justfile.pipeline coverage-pipeline  # Coverage testing only"
    @echo "  just -f justfile.pipeline benchmark-pipeline # Benchmarking only"
    @echo "  just -f justfile.pipeline regression-pipeline DIR # Compare with baseline"
    @echo ""
    @echo "Utilities:"
    @echo "  just -f justfile.pipeline stop-dev           # Stop development environment"
    @echo "  just -f justfile.pipeline results            # Show available results"
    @echo "  just -f justfile.pipeline clean              # Clean all results"
    @echo ""
    @echo "Examples:"
    @echo "  just -f justfile.pipeline mega-pipeline"
    @echo "  just -f justfile.pipeline regression-pipeline pipeline_results/benchmarks_20240101_120000"